# Dashboard Patterns

Canonical dashboard structure and patterns. This file is the single source of truth for section headings, emojis, and ordering. Both dashboard regeneration (`/work`) and validation (`/health-check`) reference this file.

---

## Canonical Dashboard Template

The dashboard **must** contain these sections in this exact order. Section headings (including emojis) are fixed â€” do not vary them.

### Metadata Block

Immediately after the `# Dashboard` title, include a hidden metadata block:
```markdown
<!-- DASHBOARD META
generated: 2026-01-28T14:30:00Z
task_hash: sha256:abc123...
task_count: 15
verification_debt: 0
drift_deferrals: 0
-->
```

This enables `/work` Step 1a to detect dashboard staleness.

### Header Line

Below the metadata block, include:
```
*Regenerated by `/work` after task changes. May be stale if tasks were modified outside `/work`.*
```

### Section Definitions

| # | Heading | Emoji | Purpose |
|---|---------|-------|---------|
| 1 | `# Dashboard` | â€” | Title (followed by metadata block and header line) |
| 2 | `## Project Context` | â€” | Project metadata table (name, stage, start date) |
| 3 | `## ğŸš¨ Needs Your Attention` | ğŸš¨ | Consolidated attention: decisions pending, human tasks, reviews, **verification debt** |
| 4 | `## Quick Status` | â€” | Overall completion %, summary counts by owner |
| 5 | `## ğŸ“ Spec Alignment` | ğŸ“ | Drift status per section, reconciliation debt (NEW) |
| 6 | `## ğŸ›¤ï¸ Critical Path` | ğŸ›¤ï¸ | Dependency chain to completion with owner indicators |
| 7 | `## ğŸ¤– Claude Status` | ğŸ¤– | In Progress / Ready to Start / Blocked for Claude tasks |
| 8 | `## ğŸ“Š Progress This Week` | ğŸ“Š | Completed/Started/Created counts, recently completed list |
| 9 | `## ğŸ“‹ All Decisions` | ğŸ“‹ | Decision log table |
| 9a | `## ğŸ”¬ Evaluation Choices` | ğŸ”¬ | Technical/methodological choices with weighted scoring (optional, appears when relevant decisions exist) |
| 10 | `## ğŸ“ All Tasks` | ğŸ“ | Full task table with summary line |
| 11 | `## ğŸ’¡ Notes & Ideas` | ğŸ’¡ | User-preserved section between `<!-- USER SECTION -->` markers |

### Section Toggle Configuration

Users can control which sections Claude builds by adding a `dashboard_sections` block to the spec frontmatter or to a `dashboard-config` section in `.claude/CLAUDE.md`:

```yaml
# In spec frontmatter or .claude/CLAUDE.md
dashboard_sections:
  project_context: build        # actively create/update
  needs_attention: build
  quick_status: build
  spec_alignment: build         # drift status per section
  critical_path: build
  claude_status: build
  progress: build
  all_decisions: maintain       # preserve existing, minor updates only
  evaluation_choices: build     # appears when technical_choice/methodological_choice decisions exist
  all_tasks: build
  notes: preserve               # always preserved (never overwritten)
```

**Modes:**
| Mode | Behavior |
|------|----------|
| `build` | Actively generate from source data on every regeneration (default) |
| `maintain` | Keep existing content, only update if data changes significantly |
| `exclude` | Skip this section entirely during regeneration |
| `preserve` | Never modify (Notes & Ideas always uses this) |

**Default:** If no configuration exists, all sections default to `build`.

**Where to configure:** Add `dashboard_sections` to the YAML frontmatter in `spec_v{N}.md`, or add a `## Dashboard Configuration` section in `.claude/CLAUDE.md` with the toggles. The spec frontmatter takes precedence.

### Regeneration Rules

When regenerating the dashboard:
1. **Read all `task-*.json` files** â€” tasks are the source of truth, not the previous dashboard
2. **Read all `decision-*.md` files** â€” decisions are the source of truth
3. **Preserve the Notes & Ideas section** â€” content between `<!-- USER SECTION -->` and `<!-- END USER SECTION -->` markers must be kept verbatim
4. **Use the exact headings above** â€” no emoji substitution, no heading rewording
5. **Separate sections with `---`** horizontal rules

### Regeneration Checklist

Every dashboard regeneration MUST complete these steps. All commands and agents that regenerate the dashboard reference this checklist to ensure consistency.

1. **Read source data**
   - All `task-*.json` files (tasks)
   - All `decision-*.md` files in `.claude/support/decisions/` (decisions)
   - `drift-deferrals.json` (if exists)
   - `verification-result.json` (if exists)

2. **Backup user section**
   - Extract content between `<!-- USER SECTION -->` and `<!-- END USER SECTION -->`
   - Save to `.claude/support/workspace/dashboard-notes-backup.md`
   - Rotate old backups (keep last 3)

3. **Generate dashboard**
   - Use exact section headings from Section Definitions table above
   - Check `dashboard_sections` config (spec frontmatter or `.claude/CLAUDE.md`)
   - Respect `build`/`maintain`/`exclude`/`preserve` modes
   - Enforce atomicity: only tasks with JSON files, only decisions with MD files

4. **Compute and add metadata block** (after `# Dashboard` title)
   ```
   <!-- DASHBOARD META
   generated: [ISO timestamp]
   task_hash: sha256:[hash of sorted task_id:status pairs, sorted lexicographically by task_id]
   task_count: [number]
   verification_debt: [count of tasks needing verification]
   drift_deferrals: [count from drift-deferrals.json]
   -->
   ```

5. **Restore user section**
   - Insert backed-up content between markers
   - If markers missing, append with warning comment: `<!-- WARNING: USER SECTION markers were missing. Content restored below. -->`

6. **Add footer line** (at very end)
   ```
   ---
   *Dashboard generated: [timestamp] | Tasks: N | [status indicator]*
   ```
   - Healthy (0 drift deferrals AND 0 verification debt): `[Spec aligned](# "0 drift deferrals, 0 verification debt")`
   - Issues (any drift deferrals OR any verification debt): `âš ï¸ N drift deferrals, M verification debt`

### Sub-Section Structure

**Needs Your Attention** has four sub-sections:
- `### Verification Debt` â€” ERROR banner if any debt exists (see format below)
- `### Decisions Pending` â€” table: ID, Decision, Category, Priority, Blocking?
- `### Tasks Ready for You` â€” table: ID, Task, Type, Due
- `### Reviews & Approvals` â€” table: Item, Type, Context

**Claude Status** has three sub-sections:
- `### In Progress` â€” current task(s); when a parallel batch is active, shows all tasks in the batch with a batch indicator
- `### Ready to Start` â€” next available Claude tasks (optionally shows parallelism eligibility)
- `### Blocked` â€” Claude tasks blocked by dependencies, decisions, or file conflicts with in-progress tasks

### Table Formats

**Project Context:**
```
| Key | Value |
|-----|-------|
| **Project** | [name] |
| **Stage** | [phase] |
| **Started** | [date] |
```

**Quick Status:**
```
**Overall: N% complete** (X of Y tasks)

| Total | Done | â— You | ğŸ¤– Claude | ğŸ‘¥ Both | Blocked |
|-------|------|--------|-----------|---------|---------|
```

**All Tasks:**
```
| ID | Title | Status | Diff | Owner | Due | Deps |
|----|-------|--------|------|-------|-----|------|
```
- Out-of-spec tasks: prefix title with âš ï¸
- Summary line: `*Summary: X/Y complete (N%)*`

**Verification Debt (when debt > 0):**
```markdown
### Verification Debt

â›” **Verification Debt: 3 tasks** â€” Project cannot complete until resolved

| Task | Title | Issue |
|------|-------|-------|
| 5 | Login flow | Missing verification |
| 8 | API endpoints | Verification failed |
| 12 | Database schema | Missing verification |

*Run `/work` to trigger verification for these tasks.*
```

**Verification Debt (when debt = 0):**
```markdown
### Verification Debt

âœ… No verification debt
```

**Verification debt definition:**
- Tasks with `status: "Awaiting Verification"`, OR
- Tasks with `status: "Finished"` that do NOT have a `task_verification` field (legacy tasks), OR
- Tasks with `task_verification.result == "fail"`

All three categories appear in the debt table. Out-of-spec tasks (`out_of_spec: true`) are excluded from verification debt count.

**Spec Alignment:**
```markdown
## ğŸ“ Spec Alignment

| Section | Status | Tasks | Last Reconciled |
|---------|--------|-------|-----------------|
| ## Authentication | âœ… Current | 3 | 2026-01-25 |
| ## API Endpoints | âš ï¸ Deferred | 2 | (needs reconciliation) |
| ## Database | âœ… Current | 4 | 2026-01-20 |

**Drift status:** 1 section deferred (2 tasks affected)
```

**Spec Alignment (all current):**
```markdown
## ğŸ“ Spec Alignment

âœ… All sections aligned â€” no drift detected
```

**All Decisions:**
```
| ID | Title | Category | Status | Decided |
|----|-------|----------|--------|---------|
```

**Evaluation Choices (optional section):**

This section appears when decisions with `category: technical_choice` or `category: methodological_choice` exist. It provides a focused view of structured evaluations.

```markdown
## ğŸ”¬ Evaluation Choices

**Quick Stats:** 2/3 technical choices evaluated, 1/1 methodological choices evaluated

| ID | Choice | Category | Status | Score | Threshold | Result |
|----|--------|----------|--------|-------|-----------|--------|
| TC-001 | State Management | technical | âœ… Selected | 4.45 | 3.5 | Pass |
| TC-002 | API Framework | technical | ğŸ”„ Evaluating | â€” | 3.5 | â€” |
| MC-001 | Auth Strategy | methodological | âœ… Selected | 4.20 | 3.0 | Pass |

### Blocking Evaluations

*No blocking evaluations*
```

**Quick Stats calculation:**
- Count decisions by category (`technical_choice`, `methodological_choice`)
- "Evaluated" = status is `selected` or `implemented`
- Format: `X/Y technical choices evaluated, X/Y methodological choices evaluated`

**Status icons:**
| Icon | Status | Meaning |
|------|--------|---------|
| âœ… | Selected/Implemented | Decision made |
| ğŸ”„ | Evaluating/Scored | In progress |
| â³ | Draft | Not started |

**Result column:**
- `Pass` = weighted_score >= threshold
- `Fail` = weighted_score < threshold (should reconsider)
- `â€”` = not yet scored

**Blocking Evaluations sub-section:**

Show evaluations that block other work (e.g., technology choices that must be made before implementation can proceed):

```markdown
### Blocking Evaluations

| ID | Choice | Blocks | Status |
|----|--------|--------|--------|
| TC-002 | API Framework | Tasks 5, 6, 7 | ğŸ”„ Evaluating |

*These choices must be completed before blocked work can proceed.*
```

If no blocking evaluations: `*No blocking evaluations*`

**When to include this section:**
- Include if any decision has `category: technical_choice` or `category: methodological_choice`
- Exclude if no such decisions exist (don't show empty section)
- Can be explicitly excluded via `dashboard_sections.evaluation_choices: exclude`

**Empty state:**
If the section is included but all evaluations are complete:
```markdown
## ğŸ”¬ Evaluation Choices

âœ… All evaluations complete (3 technical, 1 methodological)
```

### Empty State Placeholders

When a section has no data, use italic placeholder text:
- `*No pending decisions*`
- `*No human tasks ready*`
- `*Nothing to review*`
- `*No tasks in progress*` (already plural-compatible)
- `*No Claude tasks ready*`
- `*No Claude tasks blocked*`
- `*No recent completions*`
- `*No decisions yet*`
- `*No evaluation choices*`
- `*No blocking evaluations*`
- `*No tasks yet*`
- `*No tasks defined yet*`

### Parallel Batch Display

When a parallel batch is active, the "In Progress" sub-section shows all tasks in the batch:

**Parallel mode (multiple tasks in progress):**
```markdown
### In Progress

**Parallel batch (3 tasks):**

| Task | Title | Files | Status |
|------|-------|-------|--------|
| 3 | Setup database schema | `src/db/schema.sql` | ğŸ”„ Implementing |
| 4 | Create API routes | `src/api/routes.ts` | ğŸ”„ Implementing |
| 5 | Add auth middleware | `src/middleware/auth.ts` | âœ… Verified |
```

**Sequential mode (single task, default format):**
```markdown
### In Progress

ğŸ”„ **Task 3**: Setup database schema
```

**Ready to Start with parallelism info (optional):**
```markdown
### Ready to Start

| Task | Title | Parallel-Eligible? |
|------|-------|--------------------|
| 6 | Add logging | âœ… No file conflicts |
| 7 | Write tests for auth | âš ï¸ Conflicts with task 5 (`src/middleware/auth.ts`) |
```

The parallel-eligibility column is informational only â€” shown when there are tasks in the Ready state and parallel execution is enabled.

---

## Review Item Lifecycle

Items in the **Needs Your Attention â†’ Reviews & Approvals** section follow a defined lifecycle.

### What Creates Review Items

| Source | Item | Example |
|--------|------|---------|
| verify-agent | Out-of-spec task recommendations | "Add unit tests for CI" needing Accept/Reject/Defer |
| `/work` | Phase boundary approvals | "Implementation complete. Ready to verify?" |
| `/work` | Spec drift detected | "2 sections changed, 4 tasks affected" |
| implement-agent | Decision needing user input | Decision record created, awaiting approval |
| Questions system | Blocking questions | `[BLOCKING]` question in questions.md |

### When Items Are Resolved

| Item Type | Resolved When |
|-----------|---------------|
| Out-of-spec recommendations | User selects Accept/Reject/Defer for each |
| Phase boundary approvals | User confirms transition |
| Spec drift notifications | User processes reconciliation UI |
| Pending decisions | Decision status changes from `draft`/`proposed` to `approved`/`implemented` |
| Blocking questions | Question moved to Answered table in questions.md |

### Dashboard Regeneration Rules

Review items are **derived, not stored**. During regeneration:

1. **Scan for unresolved items** â€” check task files for `out_of_spec: true` without `out_of_spec_approved`, check decision files for `draft`/`proposed` status, check questions.md for unresolved blocking questions
2. **Populate the Reviews & Approvals table** from current data
3. **Never carry forward stale entries** â€” if the underlying data is resolved, the item disappears on next regeneration
4. **No dangling references** â€” every review item must link to a concrete file (task JSON, decision MD, or questions.md entry). Never write "see findings below" without the actual content.

### Preventing Staleness

Since the dashboard is regenerated from source files, review items automatically clear when:
- A task is deleted or approved â†’ removed from next regeneration
- A decision is approved â†’ no longer appears as pending
- A question is answered â†’ no longer appears as blocking

No manual cleanup is needed.

---

## Dashboard Footer

Every dashboard ends with a footer line showing generation metadata:

```markdown
---
*Dashboard generated: 2026-01-28 14:30 UTC | Tasks: 15 | [Spec aligned](# "0 drift deferrals, 0 verification debt")*
```

**When issues exist:**
```markdown
---
*Dashboard generated: 2026-01-28 14:30 UTC | Tasks: 15 | âš ï¸ 2 drift deferrals, 3 verification debt*
```

This provides at-a-glance health status without scrolling through the full dashboard.

---

## Domain-Specific Sub-Dashboards

*Added: 2026-01-27*

**Context:** When a project has a complex domain area that needs dedicated tracking beyond the main task list - such as workshop management, inventory tracking, customer pipelines, or experiment logs.

**Pattern:** Create a separate markdown file in `.claude/support/` for domain-specific tracking, then link to it from the main dashboard's Notes section.

**Structure:**
```markdown
# [Domain] Dashboard

*Last updated: [date]*

## [Key Metric 1]
| Column | Column | Column |
|--------|--------|--------|
| data   | data   | data   |

## [Key Metric 2]
...

## Quick Actions
- [ ] Action item 1
- [ ] Action item 2
```

**Example - Workshop Management:**
```markdown
# Workshop Management Dashboard

## Upcoming Sessions
| Date | Topic | Registered | Capacity | Status |
|------|-------|------------|----------|--------|
| 2026-02-15 | Intro to ML | 23 | 30 | Open |
| 2026-02-22 | Advanced NLP | 30 | 30 | Full |

## Materials Status
| Workshop | Slides | Exercises | Solutions |
|----------|--------|-----------|-----------|
| Intro to ML | âœ… | âœ… | ğŸ”„ |
| Advanced NLP | âœ… | â³ | â³ |

## Quick Actions
- [ ] Finalize ML solutions
- [ ] Create NLP exercises
```

**Why:** The main dashboard tracks tasks and project progress. Domain-specific dashboards track operational metrics unique to your project's subject matter. Separating them:
- Keeps the main dashboard focused on development progress
- Allows domain tracking to evolve independently
- Provides a single place to check domain-specific status

**When to use:**
- Project has operational concerns beyond code (events, inventory, experiments)
- You find yourself asking "what's the status of X" where X isn't a development task
- Multiple people need to track domain-specific metrics

**Linking from main dashboard:**
Add to the Notes & Ideas section:
```markdown
## ğŸ’¡ Notes & Ideas

**Quick Links:**
- [Workshop Dashboard](support/workshop-dashboard.md)
- [Experiment Log](support/experiment-log.md)

[Your notes here...]
```

---

## Critical Path Clarity

*Added: 2026-01-27*

**Context:** When multiple people (or Claude and human) are working on a project and need to know what's blocking progress.

**Pattern:** The Critical Path section shows the sequence of dependent tasks that must complete for the project to finish. Each step indicates who owns it, making handoff points clear.

**Reading the critical path:**
- â— **You**: Human action required - Claude is waiting
- ğŸ¤– **Claude**: Claude can proceed - human doesn't need to act
- ğŸ‘¥ **Both**: Collaborative task - coordinate timing

**Example:**
```markdown
## ğŸ›¤ï¸ Critical Path

**Next steps to completion:**

1. â— **You**: Review API design doc - *blocks step 2*
2. ğŸ¤– **Claude**: Implement API endpoints - *blocks step 3*
3. ğŸ‘¥ **Both**: Integration testing
4. â— **You**: Production deployment approval

*4 steps remaining on critical path*
```

**Why:** Without this view, it's easy to lose track of what's actually blocking progress vs. what's parallel work that can wait.

---

## Optional Visualizations

*Added: 2026-01-29*

**Context:** For complex projects, visual diagrams can communicate structure and progress more effectively than tables alone. These are optional additions that projects can adopt when the complexity warrants them.

**Pattern:** Create separate visualization files in `.claude/support/visualizations/` and link from the dashboard or relevant documentation.

### Recommended Visualizations

| File | Purpose | When to Use |
|------|---------|-------------|
| `workflow.md` | Phase diagram showing project stages | Multi-phase projects with distinct stages |
| `dependencies.md` | Choice dependency graph | Projects with many interconnected decisions |
| `architecture.md` | System component diagram | Complex systems with multiple services |
| `progress.md` | Status charts and timeline | Stakeholder communication, status reports |

### Example Structure

```
.claude/support/visualizations/
â”œâ”€â”€ workflow.md          # Phase flow diagram
â”œâ”€â”€ dependencies.md      # Spec-level â†’ Implementation-level choices
â”œâ”€â”€ architecture.md      # System component diagram
â””â”€â”€ progress.md          # Status pie chart, Gantt timeline
```

### Linking from Dashboard

Add to the Notes & Ideas section:
```markdown
## ğŸ’¡ Notes & Ideas

**Project Visualizations:**
- [Workflow Phases](support/visualizations/workflow.md)
- [Decision Dependencies](support/visualizations/dependencies.md)
- [System Architecture](support/visualizations/architecture.md)

[Your notes here...]
```

### Visualization File Template

```markdown
# [Visualization Name]

*Last updated: YYYY-MM-DD*

## Overview

[Brief description of what this visualization shows]

## Diagram

\`\`\`mermaid
[mermaid diagram code]
\`\`\`

## Legend

- **[Symbol/Color 1]**: [Meaning]
- **[Symbol/Color 2]**: [Meaning]

## Notes

[Any context needed to interpret the diagram]
```

### When NOT to Use Visualizations

- Simple projects with linear task lists
- When the dashboard tables already communicate clearly
- When no one will maintain them (stale diagrams are worse than none)

### Maintenance

Visualizations should be updated when:
- System architecture changes significantly
- New major decisions affect the dependency graph
- Project enters a new phase

See [Mermaid Patterns](mermaid-patterns.md) for reusable diagram templates.
